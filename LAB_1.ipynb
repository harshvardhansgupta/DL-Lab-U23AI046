{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z-2gFASXKMU",
        "outputId": "e325bd02-2052-4471-a4b2-7143b6d23ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded successfully.\n",
            "Starting training for 500 epochs...\n",
            "Epoch [50/500], Loss: 0.8695\n",
            "Epoch [100/500], Loss: 0.8434\n",
            "Epoch [150/500], Loss: 0.8253\n",
            "Epoch [200/500], Loss: 0.8093\n",
            "Epoch [250/500], Loss: 0.7941\n",
            "Epoch [300/500], Loss: 0.7785\n",
            "Epoch [350/500], Loss: 0.7614\n",
            "Epoch [400/500], Loss: 0.7434\n",
            "Epoch [450/500], Loss: 0.7227\n",
            "Epoch [500/500], Loss: 0.7025\n",
            "Training Complete.\n",
            "\n",
            "Prediction for [3, 2000]: $521550.97\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==========================================\n",
        "# 1. Load Data from CSV\n",
        "# ==========================================\n",
        "# Reads the file 'data.csv' as requested\n",
        "try:\n",
        "    df = pd.read_csv('/content/data.csv')\n",
        "    print(\"File loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'data.csv' not found. Please make sure the file is in the same directory.\")\n",
        "    exit()\n",
        "\n",
        "# Extract Input Features (bedrooms, sqft_living) and Target (price)\n",
        "# Based on the column names visible in your image\n",
        "X = df[['bedrooms', 'sqft_living']].values\n",
        "y = df[['price']].values\n",
        "\n",
        "# ==========================================\n",
        "# 2. Data Preprocessing (Crucial)\n",
        "# ==========================================\n",
        "# Neural networks require scaled data (e.g., between -1 and 1) to work correctly.\n",
        "# 'sqft_living' (e.g., 2000) and 'price' (e.g., 300000) are too large for raw training.\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_x.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Convert to PyTorch Tensors (Float32 is standard for PyTorch)\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Define Neural Network Architecture\n",
        "# ==========================================\n",
        "class RegressionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionNN, self).__init__()\n",
        "\n",
        "        # Hidden Layer: Matches the diagram with 2 input nodes -> 2 hidden nodes\n",
        "        # This handles weights w11, w12, w21, w22 and biases b1\n",
        "        self.hidden = nn.Linear(in_features=2, out_features=2)\n",
        "\n",
        "        # Output Layer: Matches the diagram with 2 hidden nodes -> 1 output node\n",
        "        # This handles weights v1, v2 and bias b2\n",
        "        self.output = nn.Linear(in_features=2, out_features=1)\n",
        "\n",
        "        # Activation Function (Relu or Sigmoid)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through hidden layer (Input -> Hidden)\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        # Pass through output layer (Hidden -> Output)\n",
        "        # No activation is used at the output for Regression problems (to allow continuous values)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the Model\n",
        "model = RegressionNN()\n",
        "\n",
        "# ==========================================\n",
        "# 4. Training Configuration\n",
        "# ==========================================\n",
        "criterion = nn.MSELoss()  # Mean Squared Error (Standard for Regression)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
        "\n",
        "# ==========================================\n",
        "# 5. Training Loop\n",
        "# ==========================================\n",
        "epochs = 500\n",
        "print(f\"Starting training for {epochs} epochs...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # 1. Forward Pass\n",
        "    predictions = model(X_tensor)\n",
        "    loss = criterion(predictions, y_tensor)\n",
        "\n",
        "    # 2. Backward Pass & Optimization\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    loss.backward()        # Calculate gradients\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Print loss every 50 epochs\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training Complete.\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. (Optional) Test with a sample prediction\n",
        "# ==========================================\n",
        "# Let's predict price for a house with 3 bedrooms and 2000 sqft_living\n",
        "with torch.no_grad():\n",
        "    sample_input = [[3, 2000]]\n",
        "    sample_scaled = scaler_x.transform(sample_input)\n",
        "    sample_tensor = torch.tensor(sample_scaled, dtype=torch.float32)\n",
        "\n",
        "    predicted_scaled = model(sample_tensor)\n",
        "    predicted_price = scaler_y.inverse_transform(predicted_scaled.numpy())\n",
        "\n",
        "    print(f\"\\nPrediction for {sample_input[0]}: ${predicted_price[0][0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==========================================\n",
        "# 1. Load Data\n",
        "# ==========================================\n",
        "try:\n",
        "    df = pd.read_csv('/content/data.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'data.csv' not found.\")\n",
        "    exit()\n",
        "\n",
        "X = df[['bedrooms', 'sqft_living']].values\n",
        "y = df[['price']].values\n",
        "\n",
        "# ==========================================\n",
        "# 2. Preprocessing\n",
        "# ==========================================\n",
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_scaled = scaler_x.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Define Neural Network\n",
        "# ==========================================\n",
        "class RegressionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionNN, self).__init__()\n",
        "        # 2 Inputs -> 2 Hidden\n",
        "        self.hidden = nn.Linear(2, 2)\n",
        "        # 2 Hidden -> 1 Output\n",
        "        self.output = nn.Linear(2, 1)\n",
        "\n",
        "        # CHANGED: Sigmoid is often better for very small \"toy\" networks than ReLU\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "model = RegressionNN()\n",
        "\n",
        "# ==========================================\n",
        "# 4. Training Config (UPDATED)\n",
        "# ==========================================\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# CHANGED: Increased lr to 0.1 and added momentum=0.9 for faster convergence\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "# ==========================================\n",
        "# 5. Training Loop (UPDATED)\n",
        "# ==========================================\n",
        "# CHANGED: Increased epochs to 2000 because 500 was not enough\n",
        "epochs = 2000\n",
        "print(f\"Starting training for {epochs} epochs...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    predictions = model(X_tensor)\n",
        "    loss = criterion(predictions, y_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print every 200 epochs to reduce clutter\n",
        "    if (epoch+1) % 200 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training Complete.\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. Test Prediction\n",
        "# ==========================================\n",
        "with torch.no_grad():\n",
        "    sample_input = [[3, 2000]]\n",
        "    sample_scaled = scaler_x.transform(sample_input)\n",
        "    sample_tensor = torch.tensor(sample_scaled, dtype=torch.float32)\n",
        "\n",
        "    predicted_scaled = model(sample_tensor)\n",
        "    predicted_price = scaler_y.inverse_transform(predicted_scaled.numpy())\n",
        "\n",
        "    print(f\"\\nInput: 3 Bedrooms, 2000 sqft\")\n",
        "    print(f\"Predicted Price: ${predicted_price[0][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj6fiC7wYVmE",
        "outputId": "4fdb9ce7-191a-4a07-bfd1-21788476a543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 2000 epochs...\n",
            "Epoch [200/2000], Loss: 0.4510\n",
            "Epoch [400/2000], Loss: 0.4464\n",
            "Epoch [600/2000], Loss: 0.4458\n",
            "Epoch [800/2000], Loss: 0.4456\n",
            "Epoch [1000/2000], Loss: 0.4455\n",
            "Epoch [1200/2000], Loss: 0.4453\n",
            "Epoch [1400/2000], Loss: 0.4447\n",
            "Epoch [1600/2000], Loss: 0.4401\n",
            "Epoch [1800/2000], Loss: 0.4385\n",
            "Epoch [2000/2000], Loss: 0.4381\n",
            "Training Complete.\n",
            "\n",
            "Input: 3 Bedrooms, 2000 sqft\n",
            "Predicted Price: $496958.97\n"
          ]
        }
      ]
    }
  ]
}